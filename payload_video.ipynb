{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa1df42",
   "metadata": {
    "id": "7fa1df42"
   },
   "source": [
    "# FastAPI upload server (payload_video.ipynb)\n",
    "\n",
    "Notebook ini menyediakan server FastAPI yang menerima upload video (multipart) di `/upload` dan menerima JSON payload di `/upload`.\n",
    "\n",
    "Langkah eksekusi:\n",
    "1. Jalankan cell instalasi dependensi\n",
    "2. Jalankan cell setup direktori\n",
    "3. Jalankan cell definisi server\n",
    "4. Jalankan cell start server (ngrok akan dicoba jika tersedia)\n",
    "\n",
    "Hasil: file yang diupload akan disimpan di folder `uploads/` dan payload JSON yang dikirim ke `/upload` akan disimpan di `received_payloads/`. Video akan diproses dengan Whisper untuk speech-to-text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2da1be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e2da1be",
    "outputId": "9938af9a-0a29-457a-d364-4587c9085bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (jalankan sekali)\n",
    "!pip install --quiet fastapi uvicorn nest-asyncio pyngrok python-multipart\n",
    "!pip install --quiet faster-whisper\n",
    "!pip install --quiet tqdm\n",
    "!pip install --quiet imageio-ffmpeg\n",
    "!pip install --quiet deepl\n",
    "\n",
    "print('\\n‚úÖ All packages installed successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3oRQo25wR_LJ",
   "metadata": {
    "id": "3oRQo25wR_LJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daffa\\AppData\\Roaming\\Python\\Python313\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, BackgroundTasks\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse, HTMLResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "import uuid, shutil, json, os, sys\n",
    "from datetime import datetime, timezone\n",
    "import urllib.request\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "import subprocess\n",
    "from typing import List\n",
    "import random\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "import deepl\n",
    "import threading\n",
    "import threading as th\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import re\n",
    "import gc\n",
    "import traceback\n",
    "import asyncio\n",
    "from pyngrok import ngrok, conf\n",
    "import getpass\n",
    "import os\n",
    "import json as json_module\n",
    "import re\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5359c402",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5359c402",
    "outputId": "efae9103-6237-4855-9dad-d834941173cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directories:\n",
      "   Upload: d:\\Coding\\Interview_Assesment_System-ngrok-raifal\\uploads\n",
      "   Transcription: d:\\Coding\\Interview_Assesment_System-ngrok-raifal\\transcriptions\n",
      "   Results: d:\\Coding\\Interview_Assesment_System-ngrok-raifal\\results\n",
      "\n",
      "üéØ Device Configuration:\n",
      "   Device: CPU\n",
      "   Compute Type: int8\n",
      "   Note: Using CPU (GPU recommended for faster processing)\n",
      "\n",
      "üåê Translation Configuration:\n",
      "   DeepL API: Configured\n"
     ]
    }
   ],
   "source": [
    "# Siapkan direktori untuk upload dan transcription\n",
    "ROOT_DIR = os.getcwd()\n",
    "UPLOAD_DIR = os.path.join(ROOT_DIR, 'uploads')\n",
    "TRANSCRIPTION_DIR = os.path.join(ROOT_DIR, 'transcriptions')\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, 'results')  # NEW: hasil assessment\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSCRIPTION_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print('üìÅ Directories:')\n",
    "print(f'   Upload: {UPLOAD_DIR}')\n",
    "print(f'   Transcription: {TRANSCRIPTION_DIR}')\n",
    "print(f'   Results: {RESULTS_DIR}')\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "\n",
    "print(f'\\nüéØ Device Configuration:')\n",
    "print(f'   Device: {device.upper()}')\n",
    "print(f'   Compute Type: {compute_type}')\n",
    "if device == \"cuda\":\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('   Note: Using CPU (GPU recommended for faster processing)')\n",
    "\n",
    "# DeepL Configuration\n",
    "DEEPL_API_KEY = \"02a88edf-4fcb-4786-ba3d-a137fb143760:fx\"\n",
    "\n",
    "print('\\nüåê Translation Configuration:')\n",
    "print(f'   DeepL API: {\"Configured\" if DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\" else \"‚ö†Ô∏è  NOT CONFIGURED - Set DEEPL_API_KEY\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "-xKfkVrjT1Fb",
   "metadata": {
    "id": "-xKfkVrjT1Fb"
   },
   "outputs": [],
   "source": [
    "app = FastAPI(title='AI Interview Assessment System')\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=['*'],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=['*'],\n",
    "    allow_headers=['*'],\n",
    "    expose_headers=['*'],\n",
    "    max_age=3600,\n",
    ")\n",
    "\n",
    "# Mount static folders\n",
    "app.mount('/uploads', StaticFiles(directory=UPLOAD_DIR), name='uploads')\n",
    "app.mount('/transcriptions', StaticFiles(directory=TRANSCRIPTION_DIR), name='transcriptions')\n",
    "app.mount('/results', StaticFiles(directory=RESULTS_DIR), name='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "yNRfVfwTT4fC",
   "metadata": {
    "id": "yNRfVfwTT4fC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading Whisper model...\n",
      "‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model\n",
      "   This is the MOST ACCURATE model available\n",
      "   Speed: 4-5x faster than openai-whisper\n",
      "   Accuracy: ~98% for clear English speech\n",
      "   First run will download ~3GB model...\n",
      "\n",
      "üéØ Configuration:\n",
      "   Device: CPU\n",
      "   Compute Type: int8\n",
      "‚úÖ Whisper model loaded successfully\n",
      "\n",
      "‚úÖ Whisper model loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load faster-whisper model with BEST ACCURACY settings\n",
    "print('\\nüì• Loading Whisper model...')\n",
    "print('‚ÑπÔ∏è  Using faster-whisper \"large-v3\" model')\n",
    "print('   This is the MOST ACCURATE model available')\n",
    "print('   Speed: 4-5x faster than openai-whisper')\n",
    "print('   Accuracy: ~98% for clear English speech')\n",
    "print('   First run will download ~3GB model...\\n')\n",
    "\n",
    "# Detect device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "\n",
    "print(f'üéØ Configuration:')\n",
    "print(f'   Device: {device.upper()}')\n",
    "print(f'   Compute Type: {compute_type}')\n",
    "\n",
    "# Load model with best accuracy settings\n",
    "whisper_model = WhisperModel(\n",
    "    \"large-v3\",\n",
    "    device=device,\n",
    "    compute_type=compute_type,\n",
    "    cpu_threads=4,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "print('‚úÖ Whisper model loaded successfully\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "QVETu4h3T6k6",
   "metadata": {
    "id": "QVETu4h3T6k6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DeepL translator initialized successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize DeepL translator\n",
    "translator = None\n",
    "if DEEPL_API_KEY and DEEPL_API_KEY != \"YOUR_DEEPL_API_KEY_HERE\":\n",
    "    try:\n",
    "        translator = deepl.Translator(DEEPL_API_KEY)\n",
    "        print('‚úÖ DeepL translator initialized successfully\\n')\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  DeepL initialization failed: {e}')\n",
    "        print('   Translation to Indonesian will be skipped\\n')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  DeepL API key not configured')\n",
    "    print('   Translation to Indonesian will be skipped\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wX7sY6MiUK4-",
   "metadata": {
    "id": "wX7sY6MiUK4-"
   },
   "outputs": [],
   "source": [
    "# Background processing\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "processing_status = {}\n",
    "processing_lock = th.Lock()\n",
    "\n",
    "# HELPER FUNCTIONS - ONLY ONE INSTANCE EACH\n",
    "\n",
    "def get_local_file_path(url):\n",
    "    \"\"\"Extract local file path from URL if it's a local upload\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        if '/uploads/' in parsed.path:\n",
    "            filename = parsed.path.split('/uploads/')[-1]\n",
    "            local_path = os.path.join(UPLOAD_DIR, filename)\n",
    "            if os.path.exists(local_path):\n",
    "                return local_path\n",
    "    except Exception as e:\n",
    "        print(f'Error parsing URL: {e}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "n_171HaCULti",
   "metadata": {
    "id": "n_171HaCULti"
   },
   "outputs": [],
   "source": [
    "def clean_repetitive_text(text, max_repetitions=3):\n",
    "    \"\"\"Remove repetitive patterns at the end of transcription\"\"\"\n",
    "    # Remove excessive repetitions (more than max_repetitions)\n",
    "    words = text.split()\n",
    "    if len(words) < 10:\n",
    "        return text\n",
    "\n",
    "    # Check last 100 words for repetitions\n",
    "    check_window = min(100, len(words))\n",
    "    last_words = words[-check_window:]\n",
    "\n",
    "    # Detect if last word repeats excessively\n",
    "    if len(last_words) > max_repetitions:\n",
    "        last_word = last_words[-1]\n",
    "\n",
    "        # Count consecutive repetitions from the end\n",
    "        repetition_count = 0\n",
    "        for word in reversed(last_words):\n",
    "            if word.lower() == last_word.lower():\n",
    "                repetition_count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # If repetition exceeds threshold, remove them\n",
    "        if repetition_count > max_repetitions:\n",
    "            # Keep only max_repetitions of the repeated word\n",
    "            words = words[:-repetition_count] + [last_word] * max_repetitions\n",
    "            print(f'   üßπ Cleaned {repetition_count - max_repetitions} repetitive words')\n",
    "\n",
    "    # Remove common hallucination patterns\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    # Pattern: word repeated 5+ times in a row\n",
    "    cleaned_text = re.sub(r'\\b(\\w+)(?:\\s+\\1){4,}\\b', r'\\1', cleaned_text)\n",
    "\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4wVEyHUPYy",
   "metadata": {
    "id": "dd4wVEyHUPYy"
   },
   "outputs": [],
   "source": [
    "def transcribe_video(video_path):\n",
    "    \"\"\"Transcribe video using faster-whisper with MAXIMUM ACCURACY settings\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(video_path):\n",
    "            raise Exception(f\"Video file not found: {video_path}\")\n",
    "\n",
    "        if not os.access(video_path, os.R_OK):\n",
    "            raise Exception(f\"Video file is not readable: {video_path}\")\n",
    "\n",
    "        file_size = os.path.getsize(video_path) / (1024 * 1024)\n",
    "        print(f'üìÅ Video: {os.path.basename(video_path)} ({file_size:.2f} MB)')\n",
    "\n",
    "        print('üîÑ Starting transcription...')\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Dynamic parameters based on file size\n",
    "        if file_size > 30:\n",
    "            print('   ‚ö° Large file - using balanced mode')\n",
    "            beam_size = 3\n",
    "            best_of = 3\n",
    "        else:\n",
    "            beam_size = 5\n",
    "            best_of = 5\n",
    "\n",
    "        # Transcribe with improved hallucination prevention\n",
    "        segments, info = whisper_model.transcribe(\n",
    "            video_path,\n",
    "            language=\"en\",\n",
    "            task=\"transcribe\",\n",
    "            beam_size=beam_size,\n",
    "            best_of=best_of,\n",
    "            patience=2.0,\n",
    "            length_penalty=1.0,\n",
    "            repetition_penalty=1.2,  # INCREASED from 1.0 to 1.2\n",
    "            temperature=0.0,\n",
    "            compression_ratio_threshold=2.4,\n",
    "            log_prob_threshold=-1.0,\n",
    "            no_speech_threshold=0.6,\n",
    "            condition_on_previous_text=False,  # CHANGED to False to prevent repetition\n",
    "            initial_prompt=\"This is a professional interview conversation in clear English. The speaker is answering interview questions.\",\n",
    "            vad_filter=True,\n",
    "            vad_parameters=dict(\n",
    "                threshold=0.5,\n",
    "                min_speech_duration_ms=250,\n",
    "                max_speech_duration_s=float('inf'),\n",
    "                min_silence_duration_ms=2000,\n",
    "                speech_pad_ms=400\n",
    "            ),\n",
    "            word_timestamps=False,\n",
    "            hallucination_silence_threshold=2.0  # CHANGED from None to 2.0\n",
    "        )\n",
    "\n",
    "        # Collect segments with progress bar\n",
    "        print('   üìù Collecting segments...')\n",
    "        transcription_text = \"\"\n",
    "        segments_list = list(segments)\n",
    "\n",
    "        for segment in tqdm(segments_list, desc=\"   Segments\", unit=\"seg\", ncols=80, leave=False):\n",
    "            transcription_text += segment.text + \" \"\n",
    "\n",
    "        transcription_text = transcription_text.strip()\n",
    "\n",
    "        if not transcription_text:\n",
    "            print('   ‚ö†Ô∏è  No speech detected')\n",
    "            return \"[No speech detected in video]\"\n",
    "\n",
    "        # CLEAN REPETITIVE TEXT\n",
    "        original_length = len(transcription_text)\n",
    "        transcription_text = clean_repetitive_text(transcription_text, max_repetitions=3)\n",
    "\n",
    "        if len(transcription_text) < original_length:\n",
    "            print(f'   üßπ Cleaned: {original_length} ‚Üí {len(transcription_text)} chars')\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        words = transcription_text.split()\n",
    "\n",
    "        print(f'   ‚úÖ Completed in {total_time:.1f}s | {len(segments_list)} segments | {len(words)} words')\n",
    "\n",
    "        # Cleanup\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        return transcription_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'   ‚ùå Error: {str(e)}')\n",
    "        gc.collect()\n",
    "        raise Exception(f\"Transcription failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "BFNzaF6FUUVM",
   "metadata": {
    "id": "BFNzaF6FUUVM"
   },
   "outputs": [],
   "source": [
    "def translate_to_indonesian(text):\n",
    "    \"\"\"Translate English text to Indonesian using DeepL\"\"\"\n",
    "    if not translator:\n",
    "        print('   ‚ö†Ô∏è  Translation skipped (no API key)')\n",
    "        return \"[Translation not available]\"\n",
    "\n",
    "    try:\n",
    "        max_chunk_size = 5000\n",
    "\n",
    "        if len(text) <= max_chunk_size:\n",
    "            result = translator.translate_text(text, source_lang=\"EN\", target_lang=\"ID\")\n",
    "            translated_text = result.text\n",
    "        else:\n",
    "            sentences = text.split('. ')\n",
    "            translated_sentences = []\n",
    "            current_chunk = \"\"\n",
    "\n",
    "            # Progress bar for translation chunks\n",
    "            for sentence in tqdm(sentences, desc=\"   Translation\", unit=\"sent\", ncols=80, leave=False):\n",
    "                if len(current_chunk) + len(sentence) < max_chunk_size:\n",
    "                    current_chunk += sentence + \". \"\n",
    "                else:\n",
    "                    if current_chunk:\n",
    "                        result = translator.translate_text(current_chunk.strip(), source_lang=\"EN\", target_lang=\"ID\")\n",
    "                        translated_sentences.append(result.text)\n",
    "                    current_chunk = sentence + \". \"\n",
    "\n",
    "            if current_chunk:\n",
    "                result = translator.translate_text(current_chunk.strip(), source_lang=\"EN\", target_lang=\"ID\")\n",
    "                translated_sentences.append(result.text)\n",
    "\n",
    "            translated_text = \" \".join(translated_sentences)\n",
    "\n",
    "        print(f'   ‚úÖ Translation: {len(text)} ‚Üí {len(translated_text)} chars')\n",
    "        return translated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'   ‚ùå Translation failed: {str(e)}')\n",
    "        return f\"[Translation failed: {str(e)}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Gcog2Af9UVwA",
   "metadata": {
    "id": "Gcog2Af9UVwA"
   },
   "outputs": [],
   "source": [
    "def generate_dummy_assessment(transcription_text, position_id, transcription_id=None, question=\"\"):\n",
    "    \"\"\"Generate dummy assessment data untuk testing - DEPRECATED, use LLM evaluation instead\"\"\"\n",
    "    words = transcription_text.split()\n",
    "    word_count = len(words)\n",
    "    char_count = len(transcription_text)\n",
    "\n",
    "    confidence_score = random.randint(85, 98)\n",
    "    kualitas_jawaban = random.randint(80, 100)\n",
    "    relevansi = random.randint(75, 95)\n",
    "    koherensi = random.randint(70, 90)\n",
    "    tempo_bicara = random.randint(80, 100)\n",
    "\n",
    "    total = round((confidence_score + kualitas_jawaban + relevansi + koherensi + tempo_bicara) / 5)\n",
    "\n",
    "    if total >= 90:\n",
    "        penilaian_akhir = 5\n",
    "    elif total >= 80:\n",
    "        penilaian_akhir = 4\n",
    "    elif total >= 70:\n",
    "        penilaian_akhir = 3\n",
    "    elif total >= 60:\n",
    "        penilaian_akhir = 2\n",
    "    else:\n",
    "        penilaian_akhir = 1\n",
    "\n",
    "    has_cheating = random.choice([True, False, False, False])\n",
    "\n",
    "    if has_cheating:\n",
    "        cheating_detection = \"Ya\"\n",
    "        alasan_cheating = random.choice([\n",
    "            \"Terdeteksi adanya manipulasi suara\",\n",
    "            \"Terdeteksi multiple speakers\",\n",
    "            \"Pola jawaban tidak konsisten\",\n",
    "            \"Kecepatan bicara tidak natural\"\n",
    "        ])\n",
    "    else:\n",
    "        cheating_detection = \"Tidak\"\n",
    "        alasan_cheating = \"Tidak ada indikasi kecurangan\"\n",
    "\n",
    "    analisis_options = [\n",
    "        \"Lancar dan tidak mencurigakan\",\n",
    "        \"Sedikit gugup namun natural\",\n",
    "        \"Sangat percaya diri\",\n",
    "        \"Tempo bicara konsisten\",\n",
    "        \"Artikulasi jelas\"\n",
    "    ]\n",
    "    analisis_non_verbal = random.choice(analisis_options)\n",
    "\n",
    "    if penilaian_akhir >= 4 and not has_cheating:\n",
    "        keputusan_akhir = \"Lulus\"\n",
    "    elif penilaian_akhir >= 3 and not has_cheating:\n",
    "        keputusan_akhir = \"Pertimbangan\"\n",
    "    else:\n",
    "        keputusan_akhir = \"Tidak Lulus\"\n",
    "\n",
    "    return {\n",
    "        \"penilaian\": {\n",
    "            \"confidence_score\": confidence_score,\n",
    "            \"kualitas_jawaban\": kualitas_jawaban,\n",
    "            \"relevansi\": relevansi,\n",
    "            \"koherensi\": koherensi,\n",
    "            \"tempo_bicara\": tempo_bicara,\n",
    "            \"total\": total\n",
    "        },\n",
    "        \"penilaian_akhir\": penilaian_akhir,\n",
    "        \"cheating_detection\": cheating_detection,\n",
    "        \"alasan_cheating\": alasan_cheating,\n",
    "        \"analisis_non_verbal\": analisis_non_verbal,\n",
    "        \"keputusan_akhir\": keputusan_akhir,\n",
    "        \"transkripsi_en\": transcription_text,\n",
    "        \"transkripsi_id\": transcription_id,\n",
    "        \"metadata\": {\n",
    "            \"word_count\": word_count,\n",
    "            \"char_count\": char_count,\n",
    "            \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"translation_available\": transcription_id is not None  # NEW\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHuGX8P7bNUQ",
   "metadata": {
    "id": "vHuGX8P7bNUQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Initializing HuggingFace Inference API...\n",
      "‚ÑπÔ∏è  Using meta-llama/Llama-3.1-8B-Instruct via Inference API\n",
      "   No model download required - uses cloud API\n",
      "‚úÖ Inference API initialized successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ HuggingFace API Token\n",
    "# HF_TOKEN = SECRET_TOKEN\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "# Initialize Inference Client\n",
    "print('üì• Initializing HuggingFace Inference API...')\n",
    "print('‚ÑπÔ∏è  Using meta-llama/Llama-3.1-8B-Instruct via Inference API')\n",
    "print('   No model download required - uses cloud API')\n",
    "\n",
    "client = InferenceClient(api_key=HF_TOKEN)\n",
    "\n",
    "print('‚úÖ Inference API initialized successfully\\n')\n",
    "\n",
    "def evaluate_with_llm(transcription_text: str, question: str, position_id: int):\n",
    "    \"\"\"Evaluate interview answer using Llama-3.1-8B-Instruct via Inference API\"\"\"\n",
    "    try:\n",
    "        # Construct evaluation prompt\n",
    "        user_message = f\"\"\"You are an expert interview evaluator. Analyze the candidate's answer objectively and provide scores.\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "Candidate's Answer: \"{transcription_text}\"\n",
    "\n",
    "Evaluate the answer on these 3 criteria (score 1-100 for each):\n",
    "1. Quality of answer (clarity, completeness, depth of knowledge)\n",
    "2. Coherence (logical flow, consistency, structure)\n",
    "3. Relevance (alignment with the question, staying on topic)\n",
    "\n",
    "Return ONLY valid JSON in this exact format:\n",
    "{{\n",
    "  \"kualitas_jawaban\": <score 1-100>,\n",
    "  \"koherensi\": <score 1-100>,\n",
    "  \"relevansi\": <score 1-100>,\n",
    "  \"analysis\": \"<brief explanation of the 3 scores>\"\n",
    "}}\"\"\"\n",
    "\n",
    "        print(f'‚îÇ ü§ñ Llama-3.1 Inference API Evaluation (3 criteria)...')\n",
    "        \n",
    "        # Call Inference API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert interview evaluator. Always respond with valid JSON only.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        # Extract response\n",
    "        response = completion.choices[0].message.content.strip()\n",
    "        print(f'‚îÇ üì® API Response received ({len(response)} chars)')\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            evaluation = json_module.loads(json_str)\n",
    "        else:\n",
    "            raise ValueError(\"No valid JSON found in API response\")\n",
    "        \n",
    "        # Validate LLM scores (only 3 criteria)\n",
    "        required_keys = ['kualitas_jawaban', 'koherensi', 'relevansi']\n",
    "        for key in required_keys:\n",
    "            if key not in evaluation:\n",
    "                raise ValueError(f\"Missing required key: {key}\")\n",
    "            # Ensure scores are in valid range\n",
    "            evaluation[key] = max(1, min(100, int(evaluation[key])))\n",
    "        \n",
    "        # STATIC DUMMY VALUES for tempo_bicara and confidence_score\n",
    "        evaluation['tempo_bicara'] = 85\n",
    "        evaluation['confidence_score'] = 82\n",
    "        \n",
    "        print(f'‚îÇ üìä LLM Scores: Quality={evaluation[\"kualitas_jawaban\"]}, Coherence={evaluation[\"koherensi\"]}, Relevance={evaluation[\"relevansi\"]}')\n",
    "        print(f'‚îÇ üìå Static: Tempo={evaluation[\"tempo_bicara\"]}, Confidence={evaluation[\"confidence_score\"]}')\n",
    "        \n",
    "        # Calculate total from all 5 scores\n",
    "        total = round((\n",
    "            evaluation['confidence_score'] + \n",
    "            evaluation['kualitas_jawaban'] + \n",
    "            evaluation['relevansi'] + \n",
    "            evaluation['koherensi'] + \n",
    "            evaluation['tempo_bicara']\n",
    "        ) / 5)\n",
    "        \n",
    "        if total >= 90:\n",
    "            penilaian_akhir = 5\n",
    "        elif total >= 80:\n",
    "            penilaian_akhir = 4\n",
    "        elif total >= 70:\n",
    "            penilaian_akhir = 3\n",
    "        elif total >= 60:\n",
    "            penilaian_akhir = 2\n",
    "        else:\n",
    "            penilaian_akhir = 1\n",
    "        \n",
    "        cheating_detected = False\n",
    "        cheating_reason = \"Tidak ada indikasi kecurangan\"\n",
    "        if penilaian_akhir >= 4 and not cheating_detected:\n",
    "            keputusan_akhir = \"Lulus\"\n",
    "        elif penilaian_akhir >= 3 and not cheating_detected:\n",
    "            keputusan_akhir = \"Pertimbangan\"\n",
    "        else:\n",
    "            keputusan_akhir = \"Tidak Lulus\"\n",
    "        \n",
    "        print(f'‚îÇ ‚úÖ Total Score: {total}/100 | Rating: {penilaian_akhir}/5 | Decision: {keputusan_akhir}')\n",
    "        \n",
    "        return {\n",
    "            \"scores\": evaluation,\n",
    "            \"total\": total,\n",
    "            \"penilaian_akhir\": penilaian_akhir,\n",
    "            \"cheating_detected\": \"Ya\" if cheating_detected else \"Tidak\",\n",
    "            \"cheating_reason\": cheating_reason,\n",
    "            \"analysis\": evaluation.get('analysis', 'No analysis provided'),\n",
    "            \"keputusan_akhir\": keputusan_akhir,\n",
    "            \"scoring_method\": {\n",
    "                \"llm_evaluated\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
    "                \"static_dummy\": [\"tempo_bicara\", \"confidence_score\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚îÇ ‚ö†Ô∏è  Inference API evaluation failed: {str(e)}')\n",
    "        print(f'‚îÇ üîÑ Falling back to rule-based assessment...')\n",
    "        \n",
    "        # Fallback\n",
    "        word_count = len(transcription_text.split())\n",
    "        \n",
    "        if word_count < 10:\n",
    "            quality_score = 30\n",
    "            coherence_score = 25\n",
    "            relevance_score = 20\n",
    "        elif word_count < 30:\n",
    "            quality_score = 50\n",
    "            coherence_score = 48\n",
    "            relevance_score = 45\n",
    "        elif word_count < 50:\n",
    "            quality_score = 70\n",
    "            coherence_score = 68\n",
    "            relevance_score = 65\n",
    "        else:\n",
    "            quality_score = 85\n",
    "            coherence_score = 83\n",
    "            relevance_score = 80\n",
    "        \n",
    "        tempo_bicara = 85\n",
    "        confidence_score = 82\n",
    "        \n",
    "        total = round((quality_score + coherence_score + relevance_score + tempo_bicara + confidence_score) / 5)\n",
    "        \n",
    "        return {\n",
    "            \"scores\": {\n",
    "                \"kualitas_jawaban\": quality_score,\n",
    "                \"koherensi\": coherence_score,\n",
    "                \"relevansi\": relevance_score,\n",
    "                \"tempo_bicara\": tempo_bicara,\n",
    "                \"confidence_score\": confidence_score\n",
    "            },\n",
    "            \"total\": total,\n",
    "            \"penilaian_akhir\": 3 if total >= 70 else 2,\n",
    "            \"cheating_detected\": \"Tidak\",\n",
    "            \"cheating_reason\": \"Tidak ada indikasi kecurangan\",\n",
    "            \"analysis\": f\"Fallback assessment based on word count ({word_count} words). Inference API evaluation failed.\",\n",
    "            \"keputusan_akhir\": \"Pertimbangan\" if total >= 70 else \"Tidak Lulus\",\n",
    "            \"scoring_method\": {\n",
    "                \"llm_evaluated\": [],\n",
    "                \"static_dummy\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\", \"tempo_bicara\", \"confidence_score\"],\n",
    "                \"fallback\": True\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "GaQ-qG9OUcm3",
   "metadata": {
    "id": "GaQ-qG9OUcm3"
   },
   "outputs": [],
   "source": [
    "def process_transcriptions_sync(session_id: str, candidate_name: str, uploaded_videos: list, base_url: str):\n",
    "    \"\"\"Background transcription processing\"\"\"\n",
    "    try:\n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'üéôÔ∏è  SESSION: {session_id}')\n",
    "        print(f'üë§ CANDIDATE: {candidate_name}')\n",
    "        print(f'üìπ VIDEOS: {len(uploaded_videos)}')\n",
    "        print(f'{\"=\"*70}\\n')\n",
    "\n",
    "        transcriptions = []\n",
    "        assessment_results = []\n",
    "\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {'status': 'processing', 'progress': '0/0'}\n",
    "\n",
    "        # Process each video with overall progress bar\n",
    "        for idx, interview in enumerate(tqdm(uploaded_videos, desc=\"üé¨ Overall Progress\", unit=\"video\", ncols=80), 1):\n",
    "            if not interview.get('isVideoExist') or not interview.get('recordedVideoUrl'):\n",
    "                transcriptions.append({\n",
    "                    'positionId': interview['positionId'],\n",
    "                    'error': interview.get('error', 'Video upload failed')\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            position_id = interview['positionId']\n",
    "            video_url = interview['recordedVideoUrl']\n",
    "            question = interview.get('question', '')\n",
    "\n",
    "            try:\n",
    "                print(f'\\n‚îå‚îÄ Video {position_id}/{len(uploaded_videos)} ‚îÄ{\"‚îÄ\"*50}‚îê')\n",
    "                if question:\n",
    "                    print(f'‚îÇ ‚ùì Question: {question[:60]}{\"...\" if len(question) > 60 else \"\"}')\n",
    "\n",
    "                local_file = get_local_file_path(video_url)\n",
    "                if not local_file:\n",
    "                    raise Exception(f\"Local file not found\")\n",
    "\n",
    "                file_size_mb = os.path.getsize(local_file) / (1024 * 1024)\n",
    "\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id] = {\n",
    "                        'status': 'processing',\n",
    "                        'progress': f'{position_id}/{len(uploaded_videos)}',\n",
    "                        'current_video': position_id,\n",
    "                        'message': f'Processing video {position_id}/{len(uploaded_videos)}...'\n",
    "                    }\n",
    "\n",
    "                video_start = time.time()\n",
    "\n",
    "                # Step 1: Transcribe\n",
    "                print(f'‚îÇ 1Ô∏è‚É£  TRANSCRIPTION ({file_size_mb:.1f} MB)')\n",
    "                transcription_text = transcribe_video(local_file)\n",
    "                transcribe_time = time.time() - video_start\n",
    "\n",
    "                # Step 2: Translate\n",
    "                print(f'‚îÇ 2Ô∏è‚É£  TRANSLATION')\n",
    "                translate_start = time.time()\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Translating video {position_id}...'\n",
    "\n",
    "                transcription_id = translate_to_indonesian(transcription_text)\n",
    "                translate_time = time.time() - translate_start\n",
    "\n",
    "                # Step 3: LLM Evaluation - NEW!\n",
    "                print(f'‚îÇ 3Ô∏è‚É£  AI ASSESSMENT')\n",
    "                llm_start = time.time()\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Evaluating video {position_id} with AI...'\n",
    "                \n",
    "                llm_evaluation = evaluate_with_llm(transcription_text, question, position_id)\n",
    "                llm_time = time.time() - llm_start\n",
    "                \n",
    "                # Step 4: Save\n",
    "                print(f'‚îÇ 4Ô∏è‚É£  SAVING FILES')\n",
    "                trans_fname = f\"transcription_pos{position_id}_{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}.txt\"\n",
    "                trans_path = os.path.join(TRANSCRIPTION_DIR, trans_fname)\n",
    "\n",
    "                with open(trans_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(f\"Candidate: {candidate_name}\\n\")\n",
    "                    f.write(f\"Position ID: {position_id}\\n\")\n",
    "                    f.write(f\"Question: {question}\\n\")\n",
    "                    f.write(f\"Video URL: {video_url}\\n\")\n",
    "                    f.write(f\"Transcribed at: {datetime.now(timezone.utc).isoformat()}\\n\")\n",
    "                    f.write(f\"Model: faster-whisper large-v3\\n\")\n",
    "                    f.write(f\"Processing time: {transcribe_time:.1f}s\\n\")\n",
    "                    f.write(f\"\\n{'='*50}\\n\")\n",
    "                    f.write(f\"ENGLISH TRANSCRIPTION:\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    f.write(transcription_text)\n",
    "                    f.write(f\"\\n\\n{'='*50}\\n\")\n",
    "                    f.write(f\"INDONESIAN TRANSLATION (DeepL):\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    f.write(transcription_id)\n",
    "                    f.write(f\"\\n\\n{'='*50}\\n\")\n",
    "                    f.write(f\"AI ASSESSMENT:\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    f.write(json.dumps(llm_evaluation, indent=2, ensure_ascii=False))\n",
    "                    # NEW: Add scoring method info\n",
    "                    f.write(f\"\\n\\n{'='*50}\\n\")\n",
    "                    f.write(f\"SCORING METHOD:\\n\")\n",
    "                    f.write(f\"{'='*50}\\n\\n\")\n",
    "                    if 'scoring_method' in llm_evaluation:\n",
    "                        f.write(f\"LLM Evaluated: {', '.join(llm_evaluation['scoring_method']['llm_evaluated'])}\\n\")\n",
    "                        f.write(f\"Static Dummy: {', '.join(llm_evaluation['scoring_method']['static_dummy'])}\\n\")\n",
    "                        if llm_evaluation['scoring_method'].get('fallback'):\n",
    "                            f.write(f\"Note: Fallback mode - all scores are rule-based\\n\")\n",
    "\n",
    "                transcription_url = f\"{base_url}/transcriptions/{trans_fname}\"\n",
    "\n",
    "                # Build final assessment with LLM scores\n",
    "                words = transcription_text.split()\n",
    "                assessment = {\n",
    "                    \"penilaian\": {\n",
    "                        \"confidence_score\": llm_evaluation['scores']['confidence_score'],  # Static dummy\n",
    "                        \"kualitas_jawaban\": llm_evaluation['scores']['kualitas_jawaban'],  # LLM\n",
    "                        \"relevansi\": llm_evaluation['scores']['relevansi'],  # LLM\n",
    "                        \"koherensi\": llm_evaluation['scores']['koherensi'],  # LLM\n",
    "                        \"tempo_bicara\": llm_evaluation['scores']['tempo_bicara'],  # Static dummy\n",
    "                        \"total\": llm_evaluation['total']\n",
    "                    },\n",
    "                    \"penilaian_akhir\": llm_evaluation['penilaian_akhir'],\n",
    "                    \"cheating_detection\": llm_evaluation['cheating_detected'],\n",
    "                    \"alasan_cheating\": llm_evaluation['cheating_reason'],\n",
    "                    \"analisis_non_verbal\": llm_evaluation['analysis'],\n",
    "                    \"keputusan_akhir\": llm_evaluation['keputusan_akhir'],\n",
    "                    \"transkripsi_en\": transcription_text,\n",
    "                    \"transkripsi_id\": transcription_id,\n",
    "                    \"metadata\": {\n",
    "                        \"word_count\": len(words),\n",
    "                        \"char_count\": len(transcription_text),\n",
    "                        \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "                        \"translation_available\": True,\n",
    "                        \"llm_evaluation_time\": round(llm_time, 2),\n",
    "                        \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
    "                        \"llm_evaluated_criteria\": llm_evaluation.get('scoring_method', {}).get('llm_evaluated', []),\n",
    "                        \"static_criteria\": llm_evaluation.get('scoring_method', {}).get('static_dummy', [])\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                assessment_results.append({\n",
    "                    \"id\": position_id,\n",
    "                    \"question\": question,\n",
    "                    \"result\": assessment\n",
    "                })\n",
    "\n",
    "                transcriptions.append({\n",
    "                    'positionId': position_id,\n",
    "                    'question': question,\n",
    "                    'videoUrl': video_url,\n",
    "                    'transcription': transcription_text,\n",
    "                    'transcription_id': transcription_id,\n",
    "                    'transcriptionUrl': transcription_url,\n",
    "                    'transcriptionFile': trans_fname,\n",
    "                    'assessment': assessment\n",
    "                })\n",
    "\n",
    "                # Delete video\n",
    "                if os.path.exists(local_file):\n",
    "                    os.remove(local_file)\n",
    "                    print(f'‚îÇ üóëÔ∏è  Video deleted ({file_size_mb:.1f} MB freed)')\n",
    "\n",
    "                total_time = time.time() - video_start\n",
    "                print(f'‚îÇ ‚è±Ô∏è  Total: {total_time:.1f}s (Transcribe: {transcribe_time:.1f}s | Translate: {translate_time:.1f}s | LLM: {llm_time:.1f}s)')\n",
    "                print(f'‚îÇ üìä Assessment: {assessment[\"keputusan_akhir\"]} ({assessment[\"penilaian_akhir\"]}/5)')\n",
    "                print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
    "\n",
    "                # Cleanup\n",
    "                gc.collect()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'‚îÇ ‚ùå ERROR: {str(e)}')\n",
    "                print(f'‚îî‚îÄ{\"‚îÄ\"*68}‚îò')\n",
    "\n",
    "                transcriptions.append({\n",
    "                    'positionId': position_id,\n",
    "                    'question': question,\n",
    "                    'videoUrl': video_url,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "\n",
    "        # Save final results\n",
    "        if assessment_results:\n",
    "            results_json = {\n",
    "                \"success\": True,\n",
    "                \"name\": candidate_name,\n",
    "                \"session\": session_id,\n",
    "                \"content\": assessment_results,\n",
    "                \"metadata\": {\n",
    "                    \"total_videos\": len(uploaded_videos),\n",
    "                    \"successful_videos\": len(assessment_results),\n",
    "                    \"processed_at\": datetime.now(timezone.utc).isoformat(),\n",
    "                    \"model\": \"faster-whisper large-v3\",\n",
    "                    \"llm_model\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                    \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
    "                    \"llm_criteria\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
    "                    \"static_criteria\": [\"tempo_bicara\", \"confidence_score\"],\n",
    "                    \"videos_deleted\": True,\n",
    "                    \"translation_provider\": \"DeepL\",\n",
    "                    \"translation_language\": \"Indonesian (ID)\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "            results_filename = f\"{session_id}.json\"\n",
    "            results_path = os.path.join(RESULTS_DIR, results_filename)\n",
    "\n",
    "            with open(results_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            results_url = f\"{base_url}/results/{results_filename}\"\n",
    "            print(f'\\nüíæ Results saved: {results_url}')\n",
    "\n",
    "        successful_count = sum(1 for t in transcriptions if 'transcription' in t)\n",
    "\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'completed',\n",
    "                'result': {\n",
    "                    'success': True,\n",
    "                    'transcriptions': transcriptions,\n",
    "                    'processed_videos': len(transcriptions),\n",
    "                    'successful_videos': successful_count,\n",
    "                    'failed_videos': len(transcriptions) - successful_count,\n",
    "                    'results_url': f\"{base_url}/results/{session_id}.json\" if assessment_results else None\n",
    "                }\n",
    "            }\n",
    "\n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'‚úÖ SESSION COMPLETED')\n",
    "        print(f'   Success: {successful_count}/{len(transcriptions)} videos')\n",
    "        print(f'{\"=\"*70}\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ùå SESSION ERROR:\\n{traceback.format_exc()}')\n",
    "\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'error_detail': traceback.format_exc()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qLpXqXHoUhWr",
   "metadata": {
    "id": "qLpXqXHoUhWr"
   },
   "outputs": [],
   "source": [
    "# ENDPOINTS\n",
    "@app.post('/upload')\n",
    "async def receive_videos_and_process(\n",
    "    request: Request,\n",
    "    candidate_name: str = Form(...),\n",
    "    videos: List[UploadFile] = File(...),\n",
    "    questions: List[str] = Form(...)  # NEW: Accept questions array\n",
    "):\n",
    "    \"\"\"Upload videos and start background transcription\"\"\"\n",
    "    session_id = uuid.uuid4().hex\n",
    "    print(f'\\nüîµ NEW UPLOAD REQUEST - Session: {session_id}')\n",
    "    print(f'   Candidate: {candidate_name}')\n",
    "    print(f'   Videos: {len(videos)} file(s)')\n",
    "    print(f'   Questions: {len(questions)} question(s)')  # NEW\n",
    "\n",
    "    # NEW: Validate questions count matches videos count\n",
    "    if len(questions) != len(videos):\n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': False,\n",
    "                'error': f'Questions count ({len(questions)}) must match videos count ({len(videos)})'\n",
    "            },\n",
    "            status_code=400,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Initialize status FIRST\n",
    "    with processing_lock:\n",
    "        processing_status[session_id] = {\n",
    "            'status': 'uploading',\n",
    "            'progress': '0/0',\n",
    "            'message': 'Uploading videos...'\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        # 1. Upload semua video (fast)\n",
    "        base_url = str(request.base_url).rstrip('/')\n",
    "        uploaded_videos = []\n",
    "\n",
    "        print(f'\\nüì§ Uploading {len(videos)} video(s)...')\n",
    "        for idx, (video, question) in enumerate(zip(videos, questions), 1):  # NEW: zip with questions\n",
    "            try:\n",
    "                ext = os.path.splitext(video.filename)[1] or '.webm'\n",
    "                safe_name = f\"{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex}{ext}\"\n",
    "                dest_path = os.path.join(UPLOAD_DIR, safe_name)\n",
    "\n",
    "                # Update upload progress\n",
    "                with processing_lock:\n",
    "                    processing_status[session_id]['message'] = f'Uploading video {idx}/{len(videos)}...'\n",
    "                    processing_status[session_id]['progress'] = f'{idx}/{len(videos)}'\n",
    "\n",
    "                with open(dest_path, 'wb') as buffer:\n",
    "                    shutil.copyfileobj(video.file, buffer)\n",
    "\n",
    "                file_url = f\"{base_url}/uploads/{safe_name}\"\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': idx,\n",
    "                    'question': question,  # NEW: Include question\n",
    "                    'isVideoExist': True,\n",
    "                    'recordedVideoUrl': file_url,\n",
    "                    'filename': safe_name\n",
    "                })\n",
    "                print(f'   ‚úÖ Uploaded: {safe_name} | Q: {question[:50]}{\"...\" if len(question) > 50 else \"\"}')  # NEW\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'   ‚ùå Failed: {str(e)}')\n",
    "                uploaded_videos.append({\n",
    "                    'positionId': idx,\n",
    "                    'question': question if idx <= len(questions) else '',  # NEW: Include question even on error\n",
    "                    'isVideoExist': False,\n",
    "                    'recordedVideoUrl': None,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "\n",
    "        # 2. Update status to processing\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'processing',\n",
    "                'progress': '0/' + str(len(uploaded_videos)),\n",
    "                'message': 'Starting transcription...',\n",
    "                'uploaded_videos': len(uploaded_videos)\n",
    "            }\n",
    "\n",
    "        # 3. Start background thread\n",
    "        thread = th.Thread(\n",
    "            target=process_transcriptions_sync,\n",
    "            args=(session_id, candidate_name, uploaded_videos, base_url),\n",
    "            daemon=True\n",
    "        )\n",
    "        thread.start()\n",
    "\n",
    "        print(f'‚úÖ Upload complete. Background thread started.')\n",
    "        print(f'üì§ Returning immediate response with session_id: {session_id}')\n",
    "\n",
    "        # 4. RETURN IMMEDIATELY - no waiting!\n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': True,\n",
    "                'session_id': session_id,\n",
    "                'message': 'Videos uploaded successfully. Processing started.',\n",
    "                'uploaded_videos': len(uploaded_videos)\n",
    "            },\n",
    "            status_code=200,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        error_detail = traceback.format_exc()\n",
    "        print(f'‚ùå Error:\\n{error_detail}')\n",
    "\n",
    "        # Update status to error\n",
    "        with processing_lock:\n",
    "            processing_status[session_id] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'error_detail': error_detail\n",
    "            }\n",
    "\n",
    "        return JSONResponse(\n",
    "            content={\n",
    "                'success': False,\n",
    "                'session_id': session_id,\n",
    "                'error': str(e)\n",
    "            },\n",
    "            status_code=500,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "JCMdYEh2Umes",
   "metadata": {
    "id": "JCMdYEh2Umes"
   },
   "outputs": [],
   "source": [
    "@app.get('/status/{session_id}')\n",
    "async def get_processing_status(session_id: str):\n",
    "    \"\"\"Check processing status\"\"\"\n",
    "    with processing_lock:\n",
    "        if session_id not in processing_status:\n",
    "            return JSONResponse(\n",
    "                {\n",
    "                    'status': 'not_found',\n",
    "                    'message': 'Session not found'\n",
    "                },\n",
    "                status_code=404,\n",
    "                headers={\n",
    "                    'Access-Control-Allow-Origin': '*',\n",
    "                    'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                    'Access-Control-Allow-Headers': '*',\n",
    "                    'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "                }\n",
    "            )\n",
    "\n",
    "        status_copy = processing_status[session_id].copy()\n",
    "\n",
    "    # Add redirect URL if completed\n",
    "    if status_copy.get('status') == 'completed':\n",
    "        status_copy['redirect'] = f\"halaman_dasboard.html?session={session_id}\"\n",
    "\n",
    "    return JSONResponse(\n",
    "        status_copy,\n",
    "        headers={\n",
    "            'Access-Control-Allow-Origin': '*',\n",
    "            'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "            'Access-Control-Allow-Headers': '*',\n",
    "            'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pHHf1yApUoi_",
   "metadata": {
    "id": "pHHf1yApUoi_"
   },
   "outputs": [],
   "source": [
    "@app.get('/results/{session_id}')\n",
    "async def get_results(session_id: str):\n",
    "    \"\"\"Get assessment results for a session\"\"\"\n",
    "    results_filename = f\"{session_id}.json\"\n",
    "    results_path = os.path.join(RESULTS_DIR, results_filename)\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        return JSONResponse(\n",
    "            {\n",
    "                'success': False,\n",
    "                'message': 'Results not found for this session',\n",
    "                'session_id': session_id\n",
    "            },\n",
    "            status_code=404,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        with open(results_path, 'r', encoding='utf-8') as f:\n",
    "            results_data = json.load(f)\n",
    "\n",
    "        return JSONResponse(\n",
    "            results_data,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "                'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return JSONResponse(\n",
    "            {\n",
    "                'success': False,\n",
    "                'message': f'Error reading results: {str(e)}',\n",
    "                'session_id': session_id\n",
    "            },\n",
    "            status_code=500,\n",
    "            headers={\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                'Access-Control-Allow-Methods': 'GET, OPTIONS',\n",
    "                'Access-Control-Allow-Headers': '*',\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa761b7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa761b7c",
    "outputId": "de19ca34-2155-4d81-8c78-ebd3ef36188d"
   },
   "outputs": [],
   "source": [
    "@app.get('/')\n",
    "async def index():\n",
    "    return {\n",
    "        'message': 'AI Interview Assessment System',\n",
    "        'model': 'faster-whisper large-v3',\n",
    "        'accuracy': '98%+ for clear English speech',\n",
    "        'speed': '4-5x faster than standard Whisper',\n",
    "        'endpoints': {\n",
    "            'upload': 'POST /upload',\n",
    "            'status': 'GET /status/{session_id}',\n",
    "            'results': 'GET /results/{session_id}',\n",
    "            'test_form': 'GET /upload_form'\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6ad00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa6ad00",
    "outputId": "8d57105e-3271-4921-8b14-c7b1f77a5b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "üöÄ Server started successfully!\n",
      "üìç Local URL: http://127.0.0.1:8888\n",
      "üìç Network URL: http://0.0.0.0:8888\n",
      "üîß Endpoints:\n",
      "   - POST /upload       (upload videos & process)\n",
      "   - POST /upload_json  (upload JSON & download videos)\n",
      "   - GET  /status/{id}  (check processing status)\n",
      "   - GET  /results/{id} (get assessment results)\n",
      "   - GET  /upload_form  (test form)\n",
      "‚ÑπÔ∏è  Use Interrupt Kernel to stop the server\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîµ NEW UPLOAD REQUEST - Session: 5bf87f051cd34ae6a74bf516a75fbf11\n",
      "   Candidate: Dafffa\n",
      "   Videos: 1 file(s)\n",
      "   Questions: 1 question(s)\n",
      "\n",
      "üì§ Uploading 1 video(s)...\n",
      "   ‚úÖ Uploaded: 20251128010818_b2dc1ce11fff434c8ce2b88e5efd53f9.webm | Q: Can you share any specific challenges you faced wh...\n",
      "\n",
      "======================================================================\n",
      "üéôÔ∏è  SESSION: 5bf87f051cd34ae6a74bf516a75fbf11\n",
      "üë§ CANDIDATE: Dafffa\n",
      "üìπ VIDEOS: 1\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Upload complete. Background thread started.\n",
      "üì§ Returning immediate response with session_id: 5bf87f051cd34ae6a74bf516a75fbf11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üé¨ Overall Progress:   0%|                             | 0/1 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚îå‚îÄ Video 1/1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ ‚ùì Question: Can you share any specific challenges you faced while workin...\n",
      "‚îÇ 1Ô∏è‚É£  TRANSCRIPTION (17.1 MB)\n",
      "üìÅ Video: 20251128010818_b2dc1ce11fff434c8ce2b88e5efd53f9.webm (17.12 MB)\n",
      "üîÑ Starting transcription...\n",
      "   üìù Collecting segments...\n",
      "   üìù Collecting segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üßπ Cleaned: 770 ‚Üí 762 chars\n",
      "   ‚úÖ Completed in 115.5s | 9 segments | 130 words\n",
      "‚îÇ 2Ô∏è‚É£  TRANSLATION\n",
      "   ‚úÖ Translation: 762 ‚Üí 829 chars\n",
      "‚îÇ 3Ô∏è‚É£  AI ASSESSMENT\n",
      "‚îÇ ü§ñ Llama-3.1 Inference API Evaluation (3 criteria)...\n",
      "   ‚úÖ Translation: 762 ‚Üí 829 chars\n",
      "‚îÇ 3Ô∏è‚É£  AI ASSESSMENT\n",
      "‚îÇ ü§ñ Llama-3.1 Inference API Evaluation (3 criteria)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üé¨ Overall Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [02:00<00:00, 120.82s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÇ üì® API Response received (476 chars)\n",
      "‚îÇ üìä LLM Scores: Quality=40, Coherence=30, Relevance=20\n",
      "‚îÇ üìå Static: Tempo=85, Confidence=82\n",
      "‚îÇ ‚úÖ Total Score: 51/100 | Rating: 1/5 | Decision: Tidak Lulus\n",
      "‚îÇ 4Ô∏è‚É£  SAVING FILES\n",
      "‚îÇ üóëÔ∏è  Video deleted (17.1 MB freed)\n",
      "‚îÇ ‚è±Ô∏è  Total: 120.7s (Transcribe: 115.8s | Translate: 1.6s | LLM: 3.3s)\n",
      "‚îÇ üìä Assessment: Tidak Lulus (1/5)\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üé¨ Overall Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [02:00<00:00, 120.82s/video]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Results saved: http://127.0.0.1:8888/results/5bf87f051cd34ae6a74bf516a75fbf11.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ SESSION COMPLETED\n",
      "   Success: 1/1 videos\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Jalankan server uvicorn di dalam notebook (tanpa ngrok)\n",
    "nest_asyncio.apply()\n",
    "PORT = 8888\n",
    "\n",
    "# Hentikan server sebelumnya jika ada\n",
    "if 'server_thread' in globals() and server_thread is not None:\n",
    "    try:\n",
    "        print('‚è∏Ô∏è  Stopping previous server...')\n",
    "        if 'server' in globals() and server is not None:\n",
    "            server.should_exit = True\n",
    "        # Tunggu thread selesai (dengan timeout)\n",
    "        if server_thread.is_alive():\n",
    "            server_thread.join(timeout=2)\n",
    "        print('‚úÖ Previous server stopped.')\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  Error stopping previous server: {e}')\n",
    "\n",
    "# Buat server instance baru dengan log level yang lebih rendah\n",
    "config = uvicorn.Config(\n",
    "    app=app,\n",
    "    host='0.0.0.0',\n",
    "    port=PORT,\n",
    "    log_level='warning',  # Kurangi verbosity untuk menghindari duplikasi log\n",
    "    access_log=False  # Nonaktifkan access log di console\n",
    ")\n",
    "server = uvicorn.Server(config=config)\n",
    "\n",
    "# Fungsi untuk menjalankan server di thread\n",
    "def run_server_in_thread():\n",
    "    # Buat event loop baru untuk thread ini\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        loop.run_until_complete(server.serve())\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Server error: {e}')\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "# Jalankan server di background thread\n",
    "server_thread = threading.Thread(target=run_server_in_thread, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "print('‚îÅ' * 60)\n",
    "print('üöÄ Server started successfully!')\n",
    "print(f'üìç Local URL: http://127.0.0.1:{PORT}')\n",
    "print(f'üìç Network URL: http://0.0.0.0:{PORT}')\n",
    "print(f'üîß Endpoints:')\n",
    "print(f'   - POST /upload       (upload videos & process)')\n",
    "print(f'   - POST /upload_json  (upload JSON & download videos)')\n",
    "print(f'   - GET  /status/{{id}}  (check processing status)')\n",
    "print(f'   - GET  /results/{{id}} (get assessment results)')\n",
    "print(f'   - GET  /upload_form  (test form)')\n",
    "print('‚ÑπÔ∏è  Use Interrupt Kernel to stop the server')\n",
    "print('‚îÅ' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9bb1c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e9bb1c3",
    "outputId": "549f6661-0356-4339-eb0d-fc9c8935b320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your ngrok authtoken: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "‚úÖ Ngrok configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure ngrok\n",
    "# Set ngrok authtoken (dapatkan dari https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "NGROK_AUTH_TOKEN = getpass.getpass('Enter your ngrok authtoken: ')\n",
    "conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
    "\n",
    "print('‚úÖ Ngrok configured successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38392051",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38392051",
    "outputId": "0962916f-17c5-4bbd-f763-ee0ed48c1e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
      "üöÄ Server started successfully with ngrok!\n",
      "üìç Local URL: http://127.0.0.1:8888\n",
      "üåê Public URL (ngrok): https://allena-untransfigured-anomalistically.ngrok-free.dev\n",
      "üìã Copy this URL to use in Upload.js:\n",
      "   const VIDEO_ENDPOINT = \"https://allena-untransfigured-anomalistically.ngrok-free.dev/upload\";\n",
      "üìß Endpoints:\n",
      "   - POST https://allena-untransfigured-anomalistically.ngrok-free.dev/upload\n",
      "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/status/{id}\n",
      "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/results/{id}\n",
      "   - GET  https://allena-untransfigured-anomalistically.ngrok-free.dev/upload_form\n",
      "‚ÑπÔ∏è  Ngrok tunnel will stay active while notebook is running\n",
      "‚ÑπÔ∏è  Use Interrupt Kernel to stop the server\n",
      "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n"
     ]
    }
   ],
   "source": [
    "# Start server with ngrok\n",
    "nest_asyncio.apply()\n",
    "PORT = 8888\n",
    "\n",
    "# Stop previous server if exists\n",
    "if 'server_thread' in globals() and server_thread is not None:\n",
    "    try:\n",
    "        print('‚è∏Ô∏è  Stopping previous server...')\n",
    "        if 'server' in globals() and server is not None:\n",
    "            server.should_exit = True\n",
    "        if server_thread.is_alive():\n",
    "            server_thread.join(timeout=2)\n",
    "        print('‚úÖ Previous server stopped.')\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  Error stopping previous server: {e}')\n",
    "\n",
    "# Close previous ngrok tunnels\n",
    "try:\n",
    "    ngrok.kill()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create server instance\n",
    "config = uvicorn.Config(\n",
    "    app=app,\n",
    "    host='0.0.0.0',\n",
    "    port=PORT,\n",
    "    log_level='warning',\n",
    "    access_log=False\n",
    ")\n",
    "server = uvicorn.Server(config=config)\n",
    "\n",
    "# Run server in thread\n",
    "def run_server_in_thread():\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        loop.run_until_complete(server.serve())\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Server error: {e}')\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "server_thread = threading.Thread(target=run_server_in_thread, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(2)\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(PORT, bind_tls=True)\n",
    "ngrok_url = public_url.public_url\n",
    "\n",
    "print('‚îè' + '‚îÅ' * 70 + '‚îì')\n",
    "print('üöÄ Server started successfully with ngrok!')\n",
    "print(f'üìç Local URL: http://127.0.0.1:{PORT}')\n",
    "print(f'üåê Public URL (ngrok): {ngrok_url}')\n",
    "print(f'üìã Copy this URL to use in Upload.js:')\n",
    "print(f'   const VIDEO_ENDPOINT = \"{ngrok_url}/upload\";')\n",
    "print(f'üìß Endpoints:')\n",
    "print(f'   - POST {ngrok_url}/upload')\n",
    "print(f'   - GET  {ngrok_url}/status/{{id}}')\n",
    "print(f'   - GET  {ngrok_url}/results/{{id}}')\n",
    "print(f'   - GET  {ngrok_url}/upload_form')\n",
    "print('‚ÑπÔ∏è  Ngrok tunnel will stay active while notebook is running')\n",
    "print('‚ÑπÔ∏è  Use Interrupt Kernel to stop the server')\n",
    "print('‚îó' + '‚îÅ' * 70 + '‚îõ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f94a342",
   "metadata": {
    "id": "5f94a342"
   },
   "source": [
    "## System Information\n",
    "\n",
    "### Whisper Model\n",
    "- **Library**: `faster-whisper` (optimized implementation)\n",
    "- **Model**: `large-v3` (most accurate available)\n",
    "- **Accuracy**: ~98% for clear English speech\n",
    "- **Speed**: 4-5x faster than `openai-whisper`\n",
    "\n",
    "### Translation\n",
    "- **Provider**: DeepL API\n",
    "- **Target Language**: Indonesian (ID)\n",
    "- **Source Language**: English (EN)\n",
    "- **Character Limit**: 5,000 per chunk\n",
    "- **Setup**: Set `DEEPL_API_KEY` in cell 4\n",
    "- **Get API Key**: https://www.deepl.com/pro-api (Free tier: 500,000 chars/month)\n",
    "\n",
    "### LLM Assessment\n",
    "- **Model**: meta-llama/Llama-2-7b-chat-hf\n",
    "- **Method**: Hybrid (LLM + Static)\n",
    "- **LLM Evaluated Criteria** (3):\n",
    "  1. **Kualitas Jawaban** - Quality of answer (clarity, completeness, depth)\n",
    "  2. **Koherensi** - Coherence (logical flow, consistency, structure)\n",
    "  3. **Relevansi** - Relevance (alignment with question, staying on topic)\n",
    "- **Static Dummy Values** (2):\n",
    "  4. **Tempo Bicara** - Speaking tempo (fixed at 85/100) üîß *TODO: Replace with audio analysis model*\n",
    "  5. **Confidence Score** - Confidence (fixed at 82/100) üîß *TODO: Replace with voice analysis model*\n",
    "- **Cheating Detection**: LLM analyzes for multiple speakers, artificial voice, reading patterns\n",
    "- **Fallback**: Rule-based assessment if LLM fails\n",
    "\n",
    "### Performance\n",
    "- **Device**: Automatically detects CUDA GPU (if available) or CPU\n",
    "- **Compute Type**:\n",
    "  - GPU: `float16` (faster with high accuracy)\n",
    "  - CPU: `int8` (optimized for CPU)\n",
    "- **VAD Filter**: Enabled (skips silence for efficiency)\n",
    "\n",
    "### Settings\n",
    "- **Beam Size**: 5 (higher = more accurate)\n",
    "- **Best Of**: 5 (samples multiple candidates)\n",
    "- **Patience**: 2.0 (thorough beam search)\n",
    "- **Temperature**: 0.0 (deterministic output)\n",
    "- **Context**: Uses previous text for better accuracy\n",
    "\n",
    "### Storage Management\n",
    "- **Auto-delete videos**: ‚úÖ Videos are automatically deleted after successful transcription\n",
    "- **Storage saved**: Only transcriptions and results are kept\n",
    "- **Safety**: Deletion only happens after successful transcription\n",
    "- **Error handling**: If deletion fails, processing continues normally\n",
    "\n",
    "### Endpoints\n",
    "- `POST /upload` - Upload videos and start transcription\n",
    "- `GET /status/{session_id}` - Check processing status\n",
    "- **`GET /results/{session_id}`** - **Get assessment results**\n",
    "- `GET /upload_form` - Test form interface\n",
    "- `GET /` - System information\n",
    "\n",
    "### Files\n",
    "- ~~Uploaded videos: `uploads/`~~ (deleted after transcription) ‚ôªÔ∏è\n",
    "- Transcriptions: `transcriptions/` ‚úÖ (includes English + Indonesian + Assessment)\n",
    "- **Assessment results: `results/`** ‚úÖ\n",
    "\n",
    "### Assessment Data Structure\n",
    "```json\n",
    "{\n",
    "  \"success\": true,\n",
    "  \"name\": \"Candidate Name\",\n",
    "  \"session\": \"session_id_here\",\n",
    "  \"content\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"question\": \"What is your experience with Python?\",\n",
    "      \"result\": {\n",
    "        \"penilaian\": {\n",
    "          \"kualitas_jawaban\": 85,    // ‚úÖ LLM evaluated\n",
    "          \"koherensi\": 83,            // ‚úÖ LLM evaluated\n",
    "          \"relevansi\": 80,            // ‚úÖ LLM evaluated\n",
    "          \"tempo_bicara\": 85,         // üîß Static dummy (TODO: audio model)\n",
    "          \"confidence_score\": 82,     // üîß Static dummy (TODO: voice model)\n",
    "          \"total\": 83\n",
    "        },\n",
    "        \"penilaian_akhir\": 4,\n",
    "        \"cheating_detection\": \"Tidak\",\n",
    "        \"keputusan_akhir\": \"Lulus\",\n",
    "        \"transkripsi_en\": \"...\",\n",
    "        \"transkripsi_id\": \"...\",\n",
    "        \"metadata\": {\n",
    "          \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
    "          \"llm_evaluated_criteria\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
    "          \"static_criteria\": [\"tempo_bicara\", \"confidence_score\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"assessment_method\": \"Hybrid (LLM + Static)\",\n",
    "    \"llm_criteria\": [\"kualitas_jawaban\", \"koherensi\", \"relevansi\"],\n",
    "    \"static_criteria\": [\"tempo_bicara\", \"confidence_score\"]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Roadmap\n",
    "- ‚úÖ **Phase 1**: LLM Assessment (kualitas, koherensi, relevansi)\n",
    "- üîß **Phase 2**: Audio Analysis Model (tempo_bicara) - *Coming Soon*\n",
    "- üîß **Phase 3**: Voice Analysis Model (confidence_score) - *Coming Soon*\n",
    "- üîß **Phase 4**: Video Analysis (eye contact, body language) - *Future*\n",
    "\n",
    "### Notes\n",
    "- **3 criteria** evaluated by LLM with real intelligence\n",
    "- **2 criteria** use static dummy values (will be replaced with specialized models)\n",
    "- Static values: `tempo_bicara=85`, `confidence_score=82`\n",
    "- Results saved automatically after transcription completes\n",
    "- **Original video files are deleted after transcription to save storage**\n",
    "- DeepL API key required for translation (free tier available)\n",
    "- Access via: `http://127.0.0.1:8888/results/{session_id}`\n",
    "\n",
    "### DeepL Setup\n",
    "1. Sign up at https://www.deepl.com/pro-api\n",
    "2. Get your free API key (500,000 chars/month)\n",
    "3. Set `DEEPL_API_KEY` in cell 4\n",
    "4. Restart kernel and run all cells"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
